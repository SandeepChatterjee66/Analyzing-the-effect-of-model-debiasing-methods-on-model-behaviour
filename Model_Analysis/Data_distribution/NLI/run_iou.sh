#!/bin/bash

# This script performs pairwise model comparisons using the K-nearest neighbors (KNN) evaluation approach. It compares the performance of different models on the same datasets by analyzing the output files generated by each model.

# Usage::

#     bash compare_models.sh

# Returns::

#     Pairwise model comparison results printed in the console.




echo $(pwd)

RESULTS_DIR="./results"

declare -a K=(10 20 50 100 200 500 800 1000)
declare -a TRAIN_DATA=("MNLI")
declare -a MODELS=("Vanilla" "Feature_sieve" "DisEnt" "LfF")
declare -a TEST_DATA=("MNLI" "SNLI")
declare -a PRED_DIRS=("MNLI" "SNLI")


for ((i=0; i<${#MODELS[@]}; i++))
do
    for ((j=i+1; j<${#MODELS[@]}; j++))
    do
        MODEL1=${MODELS[$i]}
        MODEL2=${MODELS[$j]}
        echo $MODEL1
        echo $MODEL2
        for TRAIN in ${TRAIN_DATA[@]}
        do
            for TEST in ${TEST_DATA[@]}
            do
                if [[ $TRAIN == "MNLI" ]]
                then
                    if [[ $TEST == "MNLI" ]]
                    then
                        export PRED_DIR=${PRED_DIRS[0]}
                    elif [[ $TEST == "SNLI" ]]
                    then
                        export PRED_DIR=${PRED_DIRS[1]}

                fi
                    echo "$MODEL1 vs $MODEL2"
                    echo "Running test on $TEST dataset embeddings from $TRAIN trained model for K = $k_val"
                    python3 evaluate.py --file1 $RESULTS_DIR/$MODEL1/k_$k_val/$PRED_DIR/$PRED_DIR\.pkl \
                                        --file2 $RESULTS_DIR/$MODEL2/k_$k_val/$PRED_DIR/$PRED_DIR\.pkl
                done
            done
        done
    done
done